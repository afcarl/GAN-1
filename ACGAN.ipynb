{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## This is an simple implement of ACGAN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data \n",
    "# using cifar10 data for DCGAN\n",
    "\n",
    "dataset = datasets.CIFAR10(root='data/cifar10', download=True,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Scale(32),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ])\n",
    "                                      )\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.Scale(32),\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=50, shuffle=True)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64,\n",
    "                                         shuffle=True, num_workers=int(2))\n",
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 数据加载\n",
    "1. ToTensor是指把PIL.Image(RGB) 或者numpy.ndarray(H x W x C) 从0到255的值映射到0到1的范围内，并转化成Tensor格式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 按照DCGAN网络架构中的设计进行定义"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 首先需要定义的是BN和weight filler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weight_filler(m):\n",
    "    classname = m.__class__.__name__  #获取m的类型名\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G (\n",
      "  (main): Sequential (\n",
      "    (0): ConvTranspose2d(110, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (2): ReLU (inplace)\n",
      "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (5): ReLU (inplace)\n",
      "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (8): ReLU (inplace)\n",
      "    (9): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): Tanh ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#使用一个类构建网络，\n",
    "#通过super函数继承 nn.Module的构造方法\n",
    "#使用sequential的方法构建网络模型\n",
    "\n",
    "class G(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(G, self).__init__() \n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(110, 64 * 8, 4, 1, 0, bias=False), # 64*8 kernel nums; 4 kernel size; 1 stride; 0 padding\n",
    "            nn.BatchNorm2d(64*8),\n",
    "            nn.ReLU(True),\n",
    "            # n kernel * 4 * 4\n",
    "            nn.ConvTranspose2d(64*8, 64 * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64*4),\n",
    "            nn.ReLU(True),\n",
    "            # n kernel * 8 * 8\n",
    "            nn.ConvTranspose2d(64 * 4, 64 * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64*2),\n",
    "            nn.ReLU(True),\n",
    "            # n kernel * 16 * 16\n",
    "            nn.ConvTranspose2d(64 * 2, 1, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # nc * 32 * 32\n",
    "        ) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x = x.view(x.size(0), x.size(1))\n",
    "        return self.main(x)\n",
    "g_model = G()\n",
    "print(g_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D (\n",
      "  (main): Sequential (\n",
      "    (0): Conv2d(1, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU (0.2, inplace)\n",
      "    (2): Conv2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (4): LeakyReLU (0.2, inplace)\n",
      "    (5): Conv2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (7): LeakyReLU (0.2, inplace)\n",
      "  )\n",
      "  (discrimator): Sequential (\n",
      "    (0): Conv2d(64, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): Sigmoid ()\n",
      "  )\n",
      "  (classify): Sequential (\n",
      "    (0): Linear (1024 -> 10)\n",
      "    (1): Softmax ()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 卷积操作的计算\n",
    "# (W−F+2P)/S+1 : W: input size; F: kernel size; P:padding; S: stride;\n",
    "class D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(D, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "        nn.Conv2d(1, 64 * 4, 4, 2, 1, bias=False), # 64 kernel nums; 4 kernel size; 2 stride; 1 padding\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        # state size. (ndf) x 16 x 16\n",
    "        nn.Conv2d(64 * 4, 64 * 2, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(64*2),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "         # state size. (ndf) x 8 x 8\n",
    "        nn.Conv2d(64 * 2, 64 * 1, 4, 2, 1, bias=False),\n",
    "        nn.BatchNorm2d(64*1),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "         # state size. (ndf) x 4 x 4\n",
    "        )\n",
    "        self.discrimator = nn.Sequential(\n",
    "        nn.Conv2d(64 * 1, 1, 4, 1, 0, bias=False),\n",
    "        nn.Sigmoid()\n",
    "        )\n",
    "         # final output)\n",
    "        self.classify = nn.Sequential(\n",
    "        nn.Linear(1024, 10),\n",
    "        nn.Softmax()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.main(x)\n",
    "        x_ac = x.view(-1, 1024)\n",
    "        output_D = self.discrimator(x)\n",
    "        output_C = self.classify(x_ac)\n",
    "        return output_D, output_C\n",
    "    \n",
    "d_model = D()\n",
    "print(d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_ = torch.FloatTensor(50, 1, 32, 32)\n",
    "noise = torch.FloatTensor(50, 100, 1, 1) #(batch size; 100 dimension; 1 * 1)\n",
    "fixed_noise = torch.FloatTensor(50, 100, 1, 1).normal_(0, 1)\n",
    "label = torch.FloatTensor(50)\n",
    "labels = torch.LongTensor(50)\n",
    "fix_label = torch.FloatTensor(50)\n",
    "for i in range(0,50):\n",
    "    fix_label[i] = i % 10;\n",
    "    \n",
    "fix = torch.LongTensor(50,1).copy_(fix_label)\n",
    "fix_onehot = torch.FloatTensor(50, 10)\n",
    "fix_onehot.zero_()\n",
    "fix_onehot.scatter_(1, fix, 1)\n",
    "fix_concat = [fixed_noise, fix_onehot]\n",
    "fix_concat = torch.cat(fix_concat, 1)\n",
    "input_ = Variable(input_)\n",
    "\n",
    "label = Variable(label)\n",
    "#noise = Variable(noise)\n",
    "fix_concat = Variable(fix_concat)\n",
    "#noise.data.normal_(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#weight 初始化\n",
    "g_model.apply(weight_filler)\n",
    "d_model.apply(weight_filler)\n",
    "\n",
    "# 设置求解器： DCGAN使用Adam进行求解； 学习率设置为0.0002\n",
    "optimizerD = optim.Adam(d_model.parameters(), lr = 0.0002, betas = (0.5, 0.999)) \n",
    "optimizerG = optim.Adam(g_model.parameters(), lr = 0.0002, betas = (0.5, 0.999))\n",
    "\n",
    "criterion_d = nn.BCELoss()\n",
    "criterion_ac = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/1000][0/1200] Loss_C: 0.1000 Loss_D: 1.0705 Loss_G: 0.3250 D(x): 0.5441 D(G(z)): 0.5264 / 0.3250\n",
      "[0/1000][100/1200] Loss_C: 0.1000 Loss_D: 1.1044 Loss_G: 0.0132 D(x): 0.9220 D(G(z)): 0.1824 / 0.0132\n",
      "[0/1000][200/1200] Loss_C: 0.1000 Loss_D: 1.5358 Loss_G: 0.0091 D(x): 0.9758 D(G(z)): 0.5600 / 0.0091\n",
      "[0/1000][300/1200] Loss_C: 0.1000 Loss_D: 0.9169 Loss_G: 0.0186 D(x): 0.8910 D(G(z)): 0.0258 / 0.0186\n",
      "[0/1000][400/1200] Loss_C: 0.1000 Loss_D: 1.1023 Loss_G: 0.0520 D(x): 0.9286 D(G(z)): 0.1737 / 0.0520\n",
      "[0/1000][500/1200] Loss_C: 0.1000 Loss_D: 1.0304 Loss_G: 0.0247 D(x): 0.9832 D(G(z)): 0.0473 / 0.0247\n",
      "[0/1000][600/1200] Loss_C: 0.1000 Loss_D: 0.9996 Loss_G: 0.0109 D(x): 0.9892 D(G(z)): 0.0105 / 0.0109\n",
      "[0/1000][700/1200] Loss_C: 0.1000 Loss_D: 1.0186 Loss_G: 0.0215 D(x): 0.9741 D(G(z)): 0.0446 / 0.0215\n",
      "[0/1000][800/1200] Loss_C: 0.1000 Loss_D: 1.0861 Loss_G: 0.0920 D(x): 0.8578 D(G(z)): 0.2283 / 0.0920\n",
      "[0/1000][900/1200] Loss_C: 0.1000 Loss_D: 0.7942 Loss_G: 0.1316 D(x): 0.7004 D(G(z)): 0.0937 / 0.1316\n",
      "[0/1000][1000/1200] Loss_C: 0.1000 Loss_D: 0.9867 Loss_G: 0.0394 D(x): 0.9494 D(G(z)): 0.0373 / 0.0394\n",
      "[0/1000][1100/1200] Loss_C: 0.1000 Loss_D: 1.0883 Loss_G: 0.0931 D(x): 0.8429 D(G(z)): 0.2454 / 0.0931\n",
      "[1/1000][0/1200] Loss_C: 0.1000 Loss_D: 1.5927 Loss_G: 0.3394 D(x): 0.8683 D(G(z)): 0.7243 / 0.3394\n",
      "[1/1000][100/1200] Loss_C: 0.1000 Loss_D: 1.0807 Loss_G: 0.0463 D(x): 0.9619 D(G(z)): 0.1188 / 0.0463\n",
      "[1/1000][200/1200] Loss_C: 0.1000 Loss_D: 0.1343 Loss_G: 0.8719 D(x): 0.0795 D(G(z)): 0.0548 / 0.8719\n",
      "[1/1000][300/1200] Loss_C: 0.1000 Loss_D: 1.5485 Loss_G: 0.0238 D(x): 0.9600 D(G(z)): 0.5885 / 0.0238\n",
      "[1/1000][400/1200] Loss_C: 0.1000 Loss_D: 1.0509 Loss_G: 0.0457 D(x): 0.9414 D(G(z)): 0.1095 / 0.0457\n",
      "[1/1000][500/1200] Loss_C: 0.1000 Loss_D: 0.9834 Loss_G: 0.0484 D(x): 0.9510 D(G(z)): 0.0324 / 0.0484\n",
      "[1/1000][600/1200] Loss_C: 0.1000 Loss_D: 1.1342 Loss_G: 0.2230 D(x): 0.7400 D(G(z)): 0.3942 / 0.2230\n",
      "[1/1000][700/1200] Loss_C: 0.1000 Loss_D: 1.6856 Loss_G: 0.0035 D(x): 0.9746 D(G(z)): 0.7110 / 0.0035\n",
      "[1/1000][800/1200] Loss_C: 0.1000 Loss_D: 0.8670 Loss_G: 0.2416 D(x): 0.7851 D(G(z)): 0.0819 / 0.2416\n",
      "[1/1000][900/1200] Loss_C: 0.1000 Loss_D: 1.0126 Loss_G: 0.0195 D(x): 0.9775 D(G(z)): 0.0351 / 0.0195\n",
      "[1/1000][1000/1200] Loss_C: 0.1000 Loss_D: 1.3511 Loss_G: 0.0429 D(x): 0.9470 D(G(z)): 0.4041 / 0.0429\n",
      "[1/1000][1100/1200] Loss_C: 0.1000 Loss_D: 0.7805 Loss_G: 0.3050 D(x): 0.6926 D(G(z)): 0.0879 / 0.3050\n",
      "[2/1000][0/1200] Loss_C: 0.1000 Loss_D: 0.9390 Loss_G: 0.0307 D(x): 0.9191 D(G(z)): 0.0199 / 0.0307\n",
      "[2/1000][100/1200] Loss_C: 0.1000 Loss_D: 0.9354 Loss_G: 0.1367 D(x): 0.7543 D(G(z)): 0.1811 / 0.1367\n",
      "[2/1000][200/1200] Loss_C: 0.1000 Loss_D: 1.1053 Loss_G: 0.1386 D(x): 0.7643 D(G(z)): 0.3410 / 0.1386\n",
      "[2/1000][300/1200] Loss_C: 0.1000 Loss_D: 1.0810 Loss_G: 0.0701 D(x): 0.8991 D(G(z)): 0.1819 / 0.0701\n",
      "[2/1000][400/1200] Loss_C: 0.1000 Loss_D: 0.9771 Loss_G: 0.0175 D(x): 0.9615 D(G(z)): 0.0156 / 0.0175\n",
      "[2/1000][500/1200] Loss_C: 0.1000 Loss_D: 0.8430 Loss_G: 0.2283 D(x): 0.7155 D(G(z)): 0.1275 / 0.2283\n",
      "[2/1000][600/1200] Loss_C: 0.1000 Loss_D: 0.1217 Loss_G: 0.5449 D(x): 0.1101 D(G(z)): 0.0116 / 0.5449\n",
      "[2/1000][700/1200] Loss_C: 0.1000 Loss_D: 0.3387 Loss_G: 0.5591 D(x): 0.3029 D(G(z)): 0.0358 / 0.5591\n",
      "[2/1000][800/1200] Loss_C: 0.1000 Loss_D: 1.0631 Loss_G: 0.0123 D(x): 0.9897 D(G(z)): 0.0734 / 0.0123\n",
      "[2/1000][900/1200] Loss_C: 0.1000 Loss_D: 0.6343 Loss_G: 0.2950 D(x): 0.5754 D(G(z)): 0.0589 / 0.2950\n",
      "[2/1000][1000/1200] Loss_C: 0.1000 Loss_D: 1.0686 Loss_G: 0.1392 D(x): 0.8251 D(G(z)): 0.2435 / 0.1392\n",
      "[2/1000][1100/1200] Loss_C: 0.1000 Loss_D: 0.6832 Loss_G: 0.3212 D(x): 0.5851 D(G(z)): 0.0981 / 0.3212\n",
      "[3/1000][0/1200] Loss_C: 0.1000 Loss_D: 1.0586 Loss_G: 0.0540 D(x): 0.9637 D(G(z)): 0.0949 / 0.0540\n",
      "[3/1000][100/1200] Loss_C: 0.1000 Loss_D: 0.0067 Loss_G: 0.0526 D(x): 0.0053 D(G(z)): 0.0014 / 0.0526\n",
      "[3/1000][200/1200] Loss_C: 0.1000 Loss_D: 0.9874 Loss_G: 0.1572 D(x): 0.7452 D(G(z)): 0.2422 / 0.1572\n",
      "[3/1000][300/1200] Loss_C: 0.1000 Loss_D: 1.0059 Loss_G: 0.0198 D(x): 0.9862 D(G(z)): 0.0197 / 0.0198\n",
      "[3/1000][400/1200] Loss_C: 0.1000 Loss_D: 0.9992 Loss_G: 0.0040 D(x): 0.9938 D(G(z)): 0.0054 / 0.0040\n",
      "[3/1000][500/1200] Loss_C: 0.1000 Loss_D: 0.9918 Loss_G: 0.0032 D(x): 0.9902 D(G(z)): 0.0016 / 0.0032\n",
      "[3/1000][600/1200] Loss_C: 0.1000 Loss_D: 1.0799 Loss_G: 0.1507 D(x): 0.7730 D(G(z)): 0.3069 / 0.1507\n",
      "[3/1000][700/1200] Loss_C: 0.1000 Loss_D: 1.4641 Loss_G: 0.0907 D(x): 0.9224 D(G(z)): 0.5417 / 0.0907\n",
      "[3/1000][800/1200] Loss_C: 0.1000 Loss_D: 1.1194 Loss_G: 0.0933 D(x): 0.8564 D(G(z)): 0.2630 / 0.0933\n",
      "[3/1000][900/1200] Loss_C: 0.1000 Loss_D: 1.2172 Loss_G: 0.1113 D(x): 0.8084 D(G(z)): 0.4088 / 0.1113\n",
      "[3/1000][1000/1200] Loss_C: 0.1000 Loss_D: 0.9932 Loss_G: 0.0059 D(x): 0.9876 D(G(z)): 0.0056 / 0.0059\n",
      "[3/1000][1100/1200] Loss_C: 0.1000 Loss_D: 1.0227 Loss_G: 0.0115 D(x): 0.9941 D(G(z)): 0.0286 / 0.0115\n",
      "[4/1000][0/1200] Loss_C: 0.1000 Loss_D: 1.1298 Loss_G: 0.0486 D(x): 0.9064 D(G(z)): 0.2234 / 0.0486\n",
      "[4/1000][100/1200] Loss_C: 0.1000 Loss_D: 1.3392 Loss_G: 0.1314 D(x): 0.8394 D(G(z)): 0.4998 / 0.1314\n",
      "[4/1000][200/1200] Loss_C: 0.1000 Loss_D: 0.9845 Loss_G: 0.1210 D(x): 0.8310 D(G(z)): 0.1535 / 0.1210\n",
      "[4/1000][300/1200] Loss_C: 0.1000 Loss_D: 0.9577 Loss_G: 0.1017 D(x): 0.8818 D(G(z)): 0.0759 / 0.1017\n",
      "[4/1000][400/1200] Loss_C: 0.1000 Loss_D: 0.9915 Loss_G: 0.0154 D(x): 0.9772 D(G(z)): 0.0144 / 0.0154\n",
      "[4/1000][500/1200] Loss_C: 0.1000 Loss_D: 0.9950 Loss_G: 0.0082 D(x): 0.9873 D(G(z)): 0.0077 / 0.0082\n",
      "[4/1000][600/1200] Loss_C: 0.1000 Loss_D: 1.0003 Loss_G: 0.0034 D(x): 0.9970 D(G(z)): 0.0033 / 0.0034\n",
      "[4/1000][700/1200] Loss_C: 0.1000 Loss_D: 1.0124 Loss_G: 0.0067 D(x): 0.9982 D(G(z)): 0.0142 / 0.0067\n",
      "[4/1000][800/1200] Loss_C: 0.1000 Loss_D: 1.0022 Loss_G: 0.0044 D(x): 0.9968 D(G(z)): 0.0054 / 0.0044\n",
      "[4/1000][900/1200] Loss_C: 0.1000 Loss_D: 0.9982 Loss_G: 0.0042 D(x): 0.9946 D(G(z)): 0.0037 / 0.0042\n",
      "[4/1000][1000/1200] Loss_C: 0.1000 Loss_D: 0.9989 Loss_G: 0.0027 D(x): 0.9965 D(G(z)): 0.0024 / 0.0027\n",
      "[4/1000][1100/1200] Loss_C: 0.1000 Loss_D: 1.0043 Loss_G: 0.0050 D(x): 0.9984 D(G(z)): 0.0059 / 0.0050\n",
      "[5/1000][0/1200] Loss_C: 0.1000 Loss_D: 1.0451 Loss_G: 0.1429 D(x): 0.7995 D(G(z)): 0.2457 / 0.1429\n",
      "[5/1000][100/1200] Loss_C: 0.1000 Loss_D: 1.4979 Loss_G: 0.0495 D(x): 0.9528 D(G(z)): 0.5451 / 0.0495\n",
      "[5/1000][200/1200] Loss_C: 0.1000 Loss_D: 1.0536 Loss_G: 0.0405 D(x): 0.9429 D(G(z)): 0.1107 / 0.0405\n",
      "[5/1000][300/1200] Loss_C: 0.1000 Loss_D: 1.3497 Loss_G: 0.0993 D(x): 0.9273 D(G(z)): 0.4224 / 0.0993\n",
      "[5/1000][400/1200] Loss_C: 0.1000 Loss_D: 1.0017 Loss_G: 0.0108 D(x): 0.9851 D(G(z)): 0.0166 / 0.0108\n",
      "[5/1000][500/1200] Loss_C: 0.1000 Loss_D: 0.9943 Loss_G: 0.0086 D(x): 0.9863 D(G(z)): 0.0080 / 0.0086\n",
      "[5/1000][600/1200] Loss_C: 0.1000 Loss_D: 0.9907 Loss_G: 0.0064 D(x): 0.9861 D(G(z)): 0.0046 / 0.0064\n",
      "[5/1000][700/1200] Loss_C: 0.1000 Loss_D: 1.0020 Loss_G: 0.0039 D(x): 0.9979 D(G(z)): 0.0041 / 0.0039\n",
      "[5/1000][800/1200] Loss_C: 0.1000 Loss_D: 0.9954 Loss_G: 0.0024 D(x): 0.9940 D(G(z)): 0.0014 / 0.0024\n",
      "[5/1000][900/1200] Loss_C: 0.1000 Loss_D: 1.0005 Loss_G: 0.0026 D(x): 0.9976 D(G(z)): 0.0028 / 0.0026\n",
      "[5/1000][1000/1200] Loss_C: 0.1000 Loss_D: 1.0011 Loss_G: 0.0028 D(x): 0.9988 D(G(z)): 0.0023 / 0.0028\n",
      "[5/1000][1100/1200] Loss_C: 0.1000 Loss_D: 0.9997 Loss_G: 0.0025 D(x): 0.9970 D(G(z)): 0.0027 / 0.0025\n",
      "[6/1000][0/1200] Loss_C: 0.1000 Loss_D: 0.9989 Loss_G: 0.0019 D(x): 0.9975 D(G(z)): 0.0014 / 0.0019\n",
      "[6/1000][100/1200] Loss_C: 0.1000 Loss_D: 1.0008 Loss_G: 0.0019 D(x): 0.9988 D(G(z)): 0.0020 / 0.0019\n",
      "[6/1000][200/1200] Loss_C: 0.1000 Loss_D: 1.3527 Loss_G: 0.0124 D(x): 0.9700 D(G(z)): 0.3827 / 0.0124\n",
      "[6/1000][300/1200] Loss_C: 0.1000 Loss_D: 1.3447 Loss_G: 0.0548 D(x): 0.9448 D(G(z)): 0.3999 / 0.0548\n",
      "[6/1000][400/1200] Loss_C: 0.1000 Loss_D: 0.8248 Loss_G: 0.2327 D(x): 0.7468 D(G(z)): 0.0780 / 0.2327\n",
      "[6/1000][500/1200] Loss_C: 0.1000 Loss_D: 1.0039 Loss_G: 0.0083 D(x): 0.9934 D(G(z)): 0.0105 / 0.0083\n",
      "[6/1000][600/1200] Loss_C: 0.1000 Loss_D: 1.0014 Loss_G: 0.0045 D(x): 0.9964 D(G(z)): 0.0050 / 0.0045\n",
      "[6/1000][700/1200] Loss_C: 0.1000 Loss_D: 1.0043 Loss_G: 0.0041 D(x): 0.9978 D(G(z)): 0.0064 / 0.0041\n",
      "[6/1000][800/1200] Loss_C: 0.1000 Loss_D: 0.9984 Loss_G: 0.0032 D(x): 0.9953 D(G(z)): 0.0031 / 0.0032\n",
      "[6/1000][900/1200] Loss_C: 0.1000 Loss_D: 1.0007 Loss_G: 0.0018 D(x): 0.9984 D(G(z)): 0.0023 / 0.0018\n",
      "[6/1000][1000/1200] Loss_C: 0.1000 Loss_D: 1.0028 Loss_G: 0.0032 D(x): 0.9980 D(G(z)): 0.0047 / 0.0032\n",
      "[6/1000][1100/1200] Loss_C: 0.1000 Loss_D: 1.0012 Loss_G: 0.0017 D(x): 0.9989 D(G(z)): 0.0023 / 0.0017\n",
      "[7/1000][0/1200] Loss_C: 0.1000 Loss_D: 1.0025 Loss_G: 0.0026 D(x): 0.9991 D(G(z)): 0.0035 / 0.0026\n",
      "[7/1000][100/1200] Loss_C: 0.1000 Loss_D: 1.0018 Loss_G: 0.0022 D(x): 0.9986 D(G(z)): 0.0033 / 0.0022\n",
      "[7/1000][200/1200] Loss_C: 0.1000 Loss_D: 0.9995 Loss_G: 0.0007 D(x): 0.9990 D(G(z)): 0.0006 / 0.0007\n",
      "[7/1000][300/1200] Loss_C: 0.1000 Loss_D: 1.0005 Loss_G: 0.0010 D(x): 0.9993 D(G(z)): 0.0013 / 0.0010\n",
      "[7/1000][400/1200] Loss_C: 0.1000 Loss_D: 1.0033 Loss_G: 0.0021 D(x): 0.9995 D(G(z)): 0.0038 / 0.0021\n",
      "[7/1000][500/1200] Loss_C: 0.1000 Loss_D: 1.0606 Loss_G: 0.0657 D(x): 0.8888 D(G(z)): 0.1717 / 0.0657\n",
      "[7/1000][600/1200] Loss_C: 0.1000 Loss_D: 0.8445 Loss_G: 0.0886 D(x): 0.7987 D(G(z)): 0.0458 / 0.0886\n",
      "[7/1000][700/1200] Loss_C: 0.1000 Loss_D: 1.0485 Loss_G: 0.1148 D(x): 0.8769 D(G(z)): 0.1716 / 0.1148\n",
      "[7/1000][800/1200] Loss_C: 0.1000 Loss_D: 0.7421 Loss_G: 0.3512 D(x): 0.6771 D(G(z)): 0.0650 / 0.3512\n",
      "[7/1000][900/1200] Loss_C: 0.1000 Loss_D: 0.3108 Loss_G: 0.6714 D(x): 0.2858 D(G(z)): 0.0250 / 0.6714\n",
      "[7/1000][1000/1200] Loss_C: 0.1000 Loss_D: 1.1785 Loss_G: 0.1482 D(x): 0.9342 D(G(z)): 0.2443 / 0.1482\n",
      "[7/1000][1100/1200] Loss_C: 0.1000 Loss_D: 0.8938 Loss_G: 0.1863 D(x): 0.8117 D(G(z)): 0.0822 / 0.1863\n",
      "[8/1000][0/1200] Loss_C: 0.1000 Loss_D: 1.0393 Loss_G: 0.0449 D(x): 0.9550 D(G(z)): 0.0843 / 0.0449\n",
      "[8/1000][100/1200] Loss_C: 0.1000 Loss_D: 0.9923 Loss_G: 0.0107 D(x): 0.9837 D(G(z)): 0.0086 / 0.0107\n",
      "[8/1000][200/1200] Loss_C: 0.1000 Loss_D: 1.0083 Loss_G: 0.0088 D(x): 0.9933 D(G(z)): 0.0150 / 0.0088\n",
      "[8/1000][300/1200] Loss_C: 0.1000 Loss_D: 1.0031 Loss_G: 0.0066 D(x): 0.9945 D(G(z)): 0.0085 / 0.0066\n",
      "[8/1000][400/1200] Loss_C: 0.1000 Loss_D: 1.0051 Loss_G: 0.0035 D(x): 0.9985 D(G(z)): 0.0066 / 0.0035\n",
      "[8/1000][500/1200] Loss_C: 0.1000 Loss_D: 1.0014 Loss_G: 0.0029 D(x): 0.9981 D(G(z)): 0.0033 / 0.0029\n",
      "[8/1000][600/1200] Loss_C: 0.1000 Loss_D: 1.0011 Loss_G: 0.0021 D(x): 0.9985 D(G(z)): 0.0027 / 0.0021\n",
      "[8/1000][700/1200] Loss_C: 0.1000 Loss_D: 1.0025 Loss_G: 0.0036 D(x): 0.9987 D(G(z)): 0.0039 / 0.0036\n",
      "[8/1000][800/1200] Loss_C: 0.1000 Loss_D: 1.0008 Loss_G: 0.0019 D(x): 0.9987 D(G(z)): 0.0021 / 0.0019\n",
      "[8/1000][900/1200] Loss_C: 0.1000 Loss_D: 0.9963 Loss_G: 0.0010 D(x): 0.9955 D(G(z)): 0.0008 / 0.0010\n",
      "[8/1000][1000/1200] Loss_C: 0.1000 Loss_D: 1.0003 Loss_G: 0.0014 D(x): 0.9987 D(G(z)): 0.0016 / 0.0014\n",
      "[8/1000][1100/1200] Loss_C: 0.1000 Loss_D: 0.9886 Loss_G: 0.0805 D(x): 0.8493 D(G(z)): 0.1393 / 0.0805\n",
      "[9/1000][0/1200] Loss_C: 0.1000 Loss_D: 0.9673 Loss_G: 0.0236 D(x): 0.9548 D(G(z)): 0.0125 / 0.0236\n",
      "[9/1000][100/1200] Loss_C: 0.1000 Loss_D: 1.0106 Loss_G: 0.0333 D(x): 0.9324 D(G(z)): 0.0782 / 0.0333\n",
      "[9/1000][200/1200] Loss_C: 0.1000 Loss_D: 0.9720 Loss_G: 0.1505 D(x): 0.7812 D(G(z)): 0.1908 / 0.1505\n",
      "[9/1000][300/1200] Loss_C: 0.1000 Loss_D: 0.8612 Loss_G: 0.1362 D(x): 0.7914 D(G(z)): 0.0698 / 0.1362\n",
      "[9/1000][400/1200] Loss_C: 0.1000 Loss_D: 0.1731 Loss_G: 0.9090 D(x): 0.1467 D(G(z)): 0.0264 / 0.9090\n",
      "[9/1000][500/1200] Loss_C: 0.1000 Loss_D: 1.2731 Loss_G: 0.0077 D(x): 0.9890 D(G(z)): 0.2841 / 0.0077\n",
      "[9/1000][600/1200] Loss_C: 0.1000 Loss_D: 0.9845 Loss_G: 0.0157 D(x): 0.9742 D(G(z)): 0.0104 / 0.0157\n",
      "[9/1000][700/1200] Loss_C: 0.1000 Loss_D: 0.7884 Loss_G: 0.3072 D(x): 0.7323 D(G(z)): 0.0561 / 0.3072\n",
      "[9/1000][800/1200] Loss_C: 0.1000 Loss_D: 1.0083 Loss_G: 0.0078 D(x): 0.9926 D(G(z)): 0.0157 / 0.0078\n",
      "[9/1000][900/1200] Loss_C: 0.1000 Loss_D: 1.0159 Loss_G: 0.0062 D(x): 0.9984 D(G(z)): 0.0175 / 0.0062\n",
      "[9/1000][1000/1200] Loss_C: 0.1000 Loss_D: 0.9984 Loss_G: 0.0040 D(x): 0.9944 D(G(z)): 0.0040 / 0.0040\n",
      "[9/1000][1100/1200] Loss_C: 0.1000 Loss_D: 0.8208 Loss_G: 0.0995 D(x): 0.6825 D(G(z)): 0.1383 / 0.0995\n",
      "[10/1000][0/1200] Loss_C: 0.1000 Loss_D: 1.1695 Loss_G: 0.0223 D(x): 0.9218 D(G(z)): 0.2478 / 0.0223\n",
      "[10/1000][100/1200] Loss_C: 0.1000 Loss_D: 0.9094 Loss_G: 0.1503 D(x): 0.7641 D(G(z)): 0.1454 / 0.1503\n",
      "[10/1000][200/1200] Loss_C: 0.1000 Loss_D: 1.1399 Loss_G: 0.0480 D(x): 0.7778 D(G(z)): 0.3622 / 0.0480\n",
      "[10/1000][300/1200] Loss_C: 0.1000 Loss_D: 0.4877 Loss_G: 0.6038 D(x): 0.4508 D(G(z)): 0.0370 / 0.6038\n",
      "[10/1000][400/1200] Loss_C: 0.1000 Loss_D: 0.2078 Loss_G: 0.6091 D(x): 0.1770 D(G(z)): 0.0308 / 0.6091\n",
      "[10/1000][500/1200] Loss_C: 0.1000 Loss_D: 1.0294 Loss_G: 0.0298 D(x): 0.9732 D(G(z)): 0.0562 / 0.0298\n",
      "[10/1000][600/1200] Loss_C: 0.1000 Loss_D: 1.3817 Loss_G: 0.0105 D(x): 0.8449 D(G(z)): 0.5368 / 0.0105\n",
      "[10/1000][700/1200] Loss_C: 0.1000 Loss_D: 1.0717 Loss_G: 0.0159 D(x): 0.9698 D(G(z)): 0.1019 / 0.0159\n",
      "[10/1000][800/1200] Loss_C: 0.1000 Loss_D: 1.0052 Loss_G: 0.0079 D(x): 0.9971 D(G(z)): 0.0081 / 0.0079\n",
      "[10/1000][900/1200] Loss_C: 0.1000 Loss_D: 1.0014 Loss_G: 0.0054 D(x): 0.9953 D(G(z)): 0.0061 / 0.0054\n",
      "[10/1000][1000/1200] Loss_C: 0.1000 Loss_D: 0.9991 Loss_G: 0.0041 D(x): 0.9949 D(G(z)): 0.0042 / 0.0041\n",
      "[10/1000][1100/1200] Loss_C: 0.1000 Loss_D: 0.9999 Loss_G: 0.0032 D(x): 0.9968 D(G(z)): 0.0031 / 0.0032\n",
      "[11/1000][0/1200] Loss_C: 0.1000 Loss_D: 0.9995 Loss_G: 0.0025 D(x): 0.9971 D(G(z)): 0.0024 / 0.0025\n",
      "[11/1000][100/1200] Loss_C: 0.1000 Loss_D: 1.0018 Loss_G: 0.0021 D(x): 0.9992 D(G(z)): 0.0026 / 0.0021\n",
      "[11/1000][200/1200] Loss_C: 0.1000 Loss_D: 0.9985 Loss_G: 0.0017 D(x): 0.9970 D(G(z)): 0.0014 / 0.0017\n",
      "[11/1000][300/1200] Loss_C: 0.1000 Loss_D: 1.0021 Loss_G: 0.0023 D(x): 0.9993 D(G(z)): 0.0029 / 0.0023\n",
      "[11/1000][400/1200] Loss_C: 0.1000 Loss_D: 1.0043 Loss_G: 0.0028 D(x): 0.9995 D(G(z)): 0.0048 / 0.0028\n",
      "[11/1000][500/1200] Loss_C: 0.1000 Loss_D: 1.0011 Loss_G: 0.0021 D(x): 0.9990 D(G(z)): 0.0021 / 0.0021\n",
      "[11/1000][600/1200] Loss_C: 0.1000 Loss_D: 0.9993 Loss_G: 0.0006 D(x): 0.9987 D(G(z)): 0.0006 / 0.0006\n",
      "[11/1000][700/1200] Loss_C: 0.1000 Loss_D: 1.0011 Loss_G: 0.0019 D(x): 0.9990 D(G(z)): 0.0020 / 0.0019\n",
      "[11/1000][800/1200] Loss_C: 0.1000 Loss_D: 1.0006 Loss_G: 0.0015 D(x): 0.9988 D(G(z)): 0.0018 / 0.0015\n",
      "[11/1000][900/1200] Loss_C: 0.1000 Loss_D: 1.2685 Loss_G: 0.0017 D(x): 0.9881 D(G(z)): 0.2804 / 0.0017\n",
      "[11/1000][1000/1200] Loss_C: 0.1000 Loss_D: 1.0068 Loss_G: 0.0076 D(x): 0.9918 D(G(z)): 0.0150 / 0.0076\n",
      "[11/1000][1100/1200] Loss_C: 0.1000 Loss_D: 0.8754 Loss_G: 0.0686 D(x): 0.8115 D(G(z)): 0.0639 / 0.0686\n",
      "[12/1000][0/1200] Loss_C: 0.1000 Loss_D: 1.2375 Loss_G: 0.0042 D(x): 0.9950 D(G(z)): 0.2425 / 0.0042\n",
      "[12/1000][100/1200] Loss_C: 0.1000 Loss_D: 0.5065 Loss_G: 0.6876 D(x): 0.5035 D(G(z)): 0.0030 / 0.6876\n",
      "[12/1000][200/1200] Loss_C: 0.1000 Loss_D: 0.9035 Loss_G: 0.0343 D(x): 0.8525 D(G(z)): 0.0510 / 0.0343\n",
      "[12/1000][300/1200] Loss_C: 0.1000 Loss_D: 0.0027 Loss_G: 0.2499 D(x): 0.0027 D(G(z)): 0.0000 / 0.2499\n",
      "[12/1000][400/1200] Loss_C: 0.1000 Loss_D: 0.9916 Loss_G: 0.0464 D(x): 0.9498 D(G(z)): 0.0417 / 0.0464\n",
      "[12/1000][500/1200] Loss_C: 0.1000 Loss_D: 1.0270 Loss_G: 0.0168 D(x): 0.9813 D(G(z)): 0.0457 / 0.0168\n",
      "[12/1000][600/1200] Loss_C: 0.1000 Loss_D: 0.4888 Loss_G: 0.2818 D(x): 0.4238 D(G(z)): 0.0651 / 0.2818\n",
      "[12/1000][700/1200] Loss_C: 0.1000 Loss_D: 0.9612 Loss_G: 0.0303 D(x): 0.9519 D(G(z)): 0.0093 / 0.0303\n",
      "[12/1000][800/1200] Loss_C: 0.1000 Loss_D: 0.9475 Loss_G: 0.0307 D(x): 0.9265 D(G(z)): 0.0210 / 0.0307\n",
      "[12/1000][900/1200] Loss_C: 0.1000 Loss_D: 0.9733 Loss_G: 0.0241 D(x): 0.9491 D(G(z)): 0.0242 / 0.0241\n",
      "[12/1000][1000/1200] Loss_C: 0.1000 Loss_D: 1.0369 Loss_G: 0.0184 D(x): 0.9861 D(G(z)): 0.0508 / 0.0184\n",
      "[12/1000][1100/1200] Loss_C: 0.1000 Loss_D: 1.0624 Loss_G: 0.0219 D(x): 0.9943 D(G(z)): 0.0680 / 0.0219\n",
      "[13/1000][0/1200] Loss_C: 0.1000 Loss_D: 1.0191 Loss_G: 0.0130 D(x): 0.9961 D(G(z)): 0.0229 / 0.0130\n",
      "[13/1000][100/1200] Loss_C: 0.1000 Loss_D: 0.9984 Loss_G: 0.0040 D(x): 0.9945 D(G(z)): 0.0039 / 0.0040\n",
      "[13/1000][200/1200] Loss_C: 0.1000 Loss_D: 1.0265 Loss_G: 0.0146 D(x): 0.9933 D(G(z)): 0.0332 / 0.0146\n",
      "[13/1000][300/1200] Loss_C: 0.1000 Loss_D: 0.9227 Loss_G: 0.1061 D(x): 0.8775 D(G(z)): 0.0452 / 0.1061\n",
      "[13/1000][400/1200] Loss_C: 0.1000 Loss_D: 1.3028 Loss_G: 0.1035 D(x): 0.9516 D(G(z)): 0.3513 / 0.1035\n",
      "[13/1000][500/1200] Loss_C: 0.1000 Loss_D: 0.9110 Loss_G: 0.0930 D(x): 0.8352 D(G(z)): 0.0759 / 0.0930\n",
      "[13/1000][600/1200] Loss_C: 0.1000 Loss_D: 1.0263 Loss_G: 0.0257 D(x): 0.9719 D(G(z)): 0.0544 / 0.0257\n",
      "[13/1000][700/1200] Loss_C: 0.1000 Loss_D: 0.9228 Loss_G: 0.0897 D(x): 0.8883 D(G(z)): 0.0346 / 0.0897\n",
      "[13/1000][800/1200] Loss_C: 0.1000 Loss_D: 1.0288 Loss_G: 0.0248 D(x): 0.9450 D(G(z)): 0.0838 / 0.0248\n",
      "[13/1000][900/1200] Loss_C: 0.1000 Loss_D: 0.9361 Loss_G: 0.0244 D(x): 0.9187 D(G(z)): 0.0175 / 0.0244\n",
      "[13/1000][1000/1200] Loss_C: 0.1000 Loss_D: 0.9942 Loss_G: 0.0133 D(x): 0.9832 D(G(z)): 0.0110 / 0.0133\n",
      "[13/1000][1100/1200] Loss_C: 0.1000 Loss_D: 0.9961 Loss_G: 0.0103 D(x): 0.9863 D(G(z)): 0.0098 / 0.0103\n",
      "[14/1000][0/1200] Loss_C: 0.1000 Loss_D: 0.9962 Loss_G: 0.0063 D(x): 0.9894 D(G(z)): 0.0068 / 0.0063\n",
      "[14/1000][100/1200] Loss_C: 0.1000 Loss_D: 1.0004 Loss_G: 0.0022 D(x): 0.9976 D(G(z)): 0.0028 / 0.0022\n",
      "[14/1000][200/1200] Loss_C: 0.1000 Loss_D: 1.0011 Loss_G: 0.0019 D(x): 0.9990 D(G(z)): 0.0021 / 0.0019\n",
      "[14/1000][300/1200] Loss_C: 0.1000 Loss_D: 0.9989 Loss_G: 0.0029 D(x): 0.9964 D(G(z)): 0.0024 / 0.0029\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3db8d08f3bef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# real label is 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutput_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_C\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m#print output_C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss_D_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-f1b1966d5e15>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         )\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mx_ac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0moutput_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscrimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/container.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/conv.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 237\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     35\u001b[0m     f = ConvNd(_pair(stride), _pair(padding), _pair(dilation), False,\n\u001b[1;32m     36\u001b[0m                _pair(0), groups)\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/conv.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_view4d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_view3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/conv.pyc\u001b[0m in \u001b[0;36m_update_output\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'update_output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_grad_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/conv.pyc\u001b[0m in \u001b[0;36m_thnn\u001b[0;34m(self, fn_name, input, weight, *args)\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mimpl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_thnn_convs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthnn_class_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bufs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/_functions/conv.pyc\u001b[0m in \u001b[0;36mcall_update_output\u001b[0;34m(self, bufs, input, weight, bias)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         getattr(backend, fn.name)(backend.library_state, input, output, weight,\n\u001b[0;32m--> 234\u001b[0;31m                                   bias, *args)\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_update_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        #update the D model with real data\n",
    "        d_model.zero_grad()\n",
    "        real, labels = data\n",
    "        \n",
    "        real_label = torch.LongTensor(50).copy_(labels)\n",
    "        labels = Variable(labels)\n",
    "        batch_size = real.size(0)\n",
    "        input_.data.resize_(real.size()).copy_(real)\n",
    "        label.data.resize_(batch_size).fill_(1) # real label is 1\n",
    "        \n",
    "        output_D, output_C = d_model(input_)\n",
    "        #print output_C\n",
    "        loss_D_r = criterion_d(output_D, label)\n",
    "        loss_C = criterion_ac(output_C, labels)\n",
    "        loss_r = loss_D_r + loss_C\n",
    "        loss_r.backward()\n",
    "        D_real = output_D.data.mean()\n",
    "        C_real = output_C.data.mean()\n",
    "        #update D model with fake data\n",
    "        #noise.data.resize_(batch_size, 100, 1, 1)\n",
    "        #noise.data.normal_(0, 1)\n",
    "        label.data.fill_(0) # fake label\n",
    "        noise = torch.FloatTensor(batch_size, 100, 1, 1).normal_(0,1) \n",
    "               \n",
    "        y = torch.LongTensor(batch_size,1).copy_(real_label)\n",
    "        y_onehot = torch.FloatTensor(batch_size, 10)\n",
    "        y_onehot.zero_()\n",
    "        y_onehot.scatter_(1,y,1)\n",
    "        \n",
    "        z_concat = [noise, y_onehot]\n",
    "        z_concat = torch.cat(z_concat, 1)\n",
    "        z_concat = Variable(z_concat)\n",
    "        \n",
    "        fake_input = g_model(z_concat)\n",
    "        output_D, output_C = d_model(fake_input.detach())\n",
    "        loss_D_f = criterion_d(output_D, label)\n",
    "        loss_C_f = criterion_ac(output_C, labels)\n",
    "        loss_f = loss_D_f + loss_C_f\n",
    "        loss_f.backward()\n",
    "        D_fake = output_D.data.mean()\n",
    "        \n",
    "        errD = D_real + D_fake\n",
    "        \n",
    "        optimizerD.step()\n",
    "        \n",
    "        #update G mdoel\n",
    "        g_model.zero_grad()\n",
    "        label.data.fill_(1) # G model want the G samples be 1\n",
    "        #noise.data.resize_(batch_size, 100, 1, 1)\n",
    "        #noise.data.normal_(0, 1)\n",
    "        #fake_input = g_model(noise)\n",
    "        output_D, output_C = d_model(fake_input)\n",
    "        \n",
    "        loss_G = criterion_d(output_D, label)\n",
    "        loss_C_G = criterion_ac(output_C, labels)\n",
    "        loss_g = loss_G + loss_C_G\n",
    "        loss_g.backward()\n",
    "        loss_D_G = output_D.data.mean()\n",
    "        \n",
    "        optimizerG.step()\n",
    "        \n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print('[%d/%d][%d/%d] Loss_C: %.4f Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, 1000, i, len(train_loader),\n",
    "                 C_real, D_real + D_fake, loss_D_G, D_real, D_fake, loss_D_G ))\n",
    "            \n",
    "            vutils.save_image(real, \n",
    "                             '%s/real_sample.png' % 'logs')\n",
    "            \n",
    "            fake = g_model(fix_concat)\n",
    "            vutils.save_image(fake.data,\n",
    "                             '%s/fake_sample_epoch_%03d.png' % ('logs', epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "description": "How to do net surgery and manually change model parameters for custom use.",
  "example_name": "Editing model parameters",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "priority": 5
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
